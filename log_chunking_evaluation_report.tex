\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}

\geometry{margin=2.5cm}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Log Chunking Methods Evaluation Report}
\fancyhead[R]{\today}
\fancyfoot[C]{\thepage}

\title{\textbf{Evaluation of Chunking Methods for Log Analysis in RAG Systems}}
\author{Log Analysis System Evaluation}
\date{\today}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray}
}

\begin{document}

\maketitle
\thispagestyle{fancy}

\tableofcontents
\newpage

\section{Executive Summary}

This report presents a comprehensive evaluation of five chunking methods for log file analysis in a Retrieval-Augmented Generation (RAG) system. The evaluation is based on testing each method with a dataset of 150+ Apache web server log entries covering a 65-minute period (08:15:23 to 09:20:05 on January 8, 2026).

The chunking methods evaluated are:
\begin{itemize}
    \item \textbf{log\_semantic\_sliding}: Sliding window with 20\% overlap
    \item \textbf{log\_error\_block}: Groups errors with surrounding context
    \item \textbf{log\_time\_window}: Groups logs by hourly time windows
    \item \textbf{log\_component\_based}: Groups logs by IP address/client
    \item \textbf{log\_status\_code}: Groups logs by HTTP status code categories
\end{itemize}

\section{Dataset Overview}

\subsection{Data Characteristics}

The test dataset consists of Apache Common Log Format (CLF) entries with the following characteristics:

\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Property} & \textbf{Value} \\
\midrule
Total Log Entries & 150+ entries \\
Time Range & 08:15:23 - 09:20:05 (65 minutes) \\
Date & January 8, 2026 \\
Unique IP Addresses & 10+ distinct IPs \\
HTTP Methods & GET, POST, PUT, DELETE \\
Status Code Range & 200, 304, 401, 403, 404 \\
\bottomrule
\end{tabular}
\caption{Dataset Characteristics}
\end{table}

\subsection{IP Address Distribution}

The dataset contains requests from multiple IP addresses:
\begin{itemize}
    \item \texttt{192.168.1.45}, \texttt{192.168.1.67}, \texttt{192.168.1.89} - Internal network
    \item \texttt{10.0.0.122}, \texttt{10.0.0.155} - Private network
    \item \texttt{172.16.54.78}, \texttt{172.16.54.90} - Private network
    \item \texttt{66.249.66.1} - Googlebot (search engine crawler)
    \item \texttt{207.46.13.5}, \texttt{40.77.167.32} - Microsoft/Bingbot
\end{itemize}

\subsection{Request Types}

The logs contain various request types:
\begin{itemize}
    \item Static resources: CSS, JS, images (\texttt{/assets/*})
    \item API endpoints: \texttt{/api/*}
    \item Product pages: \texttt{/products/*}
    \item Admin operations: \texttt{/admin/*}
    \item Search queries: \texttt{/search?q=*}
    \item Cart operations: \texttt{/cart/*}
    \item Checkout process: \texttt{/checkout/*}
\end{itemize}

\section{Chunking Methods: Technical Overview}

\subsection{Method 1: log\_semantic\_sliding}

\subsubsection{Algorithm Logic}

The semantic sliding window method implements a context-preserving chunking strategy:

\begin{enumerate}
    \item \textbf{Initialization}: Processes log entries sequentially, maintaining a current chunk buffer
    \item \textbf{Chunk Creation}: When chunk size threshold (2500 characters) is reached:
    \begin{itemize}
        \item Creates a document chunk from current buffer
        \item Calculates overlap: 20\% of current chunk entries
        \item Preserves last N entries as overlap buffer
    \end{itemize}
    \item \textbf{Overlap Mechanism}: New chunk starts with overlap entries from previous chunk
    \item \textbf{Context Preservation}: Ensures no information loss at chunk boundaries
\end{enumerate}

\subsubsection{Configuration}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 20\% (percentage-based)
    \item Average entries per chunk: 8-15 log entries
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Preserves temporal context across chunk boundaries
    \item Optimal for RAG systems requiring context-aware retrieval
    \item Maintains sequence relationships between log entries
    \item Best for queries requiring multi-entry analysis
\end{itemize}

\subsubsection{Disadvantages}
\begin{itemize}
    \item Slightly higher storage overhead due to overlap
    \item May create more chunks than other methods
    \item Less efficient for single-entry queries
\end{itemize}

\subsection{Method 2: log\_error\_block}

\subsubsection{Algorithm Logic}

The error block method groups error entries with their surrounding context:

\begin{enumerate}
    \item \textbf{Error Detection}: Identifies error status codes (400, 401, 403, 404, 405, 500-504)
    \item \textbf{Context Grouping}: When an error is detected:
    \begin{itemize}
        \item Includes the error entry
        \item Includes surrounding non-error entries for context
        \item Continues until chunk size limit or non-error sequence
    \end{itemize}
    \item \textbf{Chunk Boundary}: Creates chunk when:
    \begin{itemize}
        \item Size threshold reached, OR
        \item Error block ends (error followed by non-error with multiple entries)
    \end{itemize}
\end{enumerate}

\subsubsection{Configuration}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0 (no overlap)
    \item Error status codes: 400, 401, 403, 404, 405, 500, 501, 502, 503, 504
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Excellent for error analysis and debugging
    \item Groups related error context together
    \item Efficient for security incident investigation
    \item Optimized for error-focused queries
\end{itemize}

\subsubsection{Disadvantages}
\begin{itemize}
    \item Less effective for non-error queries
    \item May fragment successful request patterns
    \item Context limited to error-adjacent entries
\end{itemize}

\subsection{Method 3: log\_time\_window}

\subsubsection{Algorithm Logic}

The time window method groups logs by temporal boundaries:

\begin{enumerate}
    \item \textbf{Timestamp Extraction}: Uses regex pattern to extract timestamps:
    \begin{lstlisting}[language=Python]
    timestamp_pattern = r'\[(\d{2})/(\w{3})/(\d{4}):(\d{2}):(\d{2}):(\d{2})'
    \end{lstlisting}
    \item \textbf{Time Window Creation}: Groups entries by hour:
    \begin{itemize}
        \item Format: \texttt{YYYY-MMM-DD\_HH:00}
        \item Example: \texttt{2026-Jan-08\_08:00}
    \end{itemize}
    \item \textbf{Chunk Boundary}: Creates chunk when:
    \begin{itemize}
        \item Size threshold reached, OR
        \item Time window changes (new hour detected)
    \end{itemize}
\end{enumerate}

\subsubsection{Configuration}
\begin{itemize}
    \item \texttt{chunk\_size}: 3000 characters
    \item \texttt{overlap\_size}: 0 (no overlap)
    \item Time granularity: Hourly windows
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Excellent for time-based analysis queries
    \item Natural grouping for traffic pattern analysis
    \item Effective for peak hour identification
    \item Maintains temporal relationships
\end{itemize}

\subsubsection{Disadvantages}
\begin{itemize}
    \item May split related requests across time boundaries
    \item Less effective for non-temporal queries
    \item Fixed time granularity (hourly) may not suit all use cases
\end{itemize}

\subsection{Method 4: log\_component\_based}

\subsubsection{Algorithm Logic}

The component-based method groups logs by client IP address:

\begin{enumerate}
    \item \textbf{IP Extraction}: Uses regex to extract IP from log line start:
    \begin{lstlisting}[language=Python]
    ip_pattern = r'^(\d+\.\d+\.\d+\.\d+)'
    \end{lstlisting}
    \item \textbf{Component Grouping}: Groups entries by same IP address
    \item \textbf{Chunk Boundary}: Creates chunk when:
    \begin{itemize}
        \item Size threshold reached, OR
        \item IP address changes (with multiple entries in current chunk)
    \end{itemize}
\end{enumerate}

\subsubsection{Configuration}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0 (no overlap)
    \item Component identifier: IP address
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Excellent for client behavior analysis
    \item Effective for suspicious activity detection
    \item Groups user sessions together
    \item Useful for IP-based queries
\end{itemize}

\subsubsection{Disadvantages}
\begin{itemize}
    \item May fragment requests from same time period
    \item Less effective for system-wide analysis
    \item Multiple IPs in same query may require multiple chunks
\end{itemize}

\subsection{Method 5: log\_status\_code}

\subsubsection{Algorithm Logic}

The status code method groups logs by HTTP response status categories:

\begin{enumerate}
    \item \textbf{Status Extraction}: Extracts 3-digit status code:
    \begin{lstlisting}[language=Python]
    status_pattern = r'" (\d{3}) '
    \end{lstlisting}
    \item \textbf{Category Classification}: Maps status codes to categories:
    \begin{itemize}
        \item \texttt{2xx\_success}: 200, 201, 204, etc.
        \item \texttt{3xx\_redirect}: 301, 302, 304, etc.
        \item \texttt{4xx\_client\_error}: 400, 401, 403, 404, etc.
        \item \texttt{5xx\_server\_error}: 500, 501, 502, 503, 504
    \end{itemize}
    \item \textbf{Chunk Boundary}: Creates chunk when:
    \begin{itemize}
        \item Size threshold reached, OR
        \item Status category changes
    \end{itemize}
\end{enumerate}

\subsubsection{Configuration}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0 (no overlap)
    \item Categories: 2xx, 3xx, 4xx, 5xx, unknown
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Excellent for performance monitoring
    \item Effective for error rate analysis
    \item Groups similar response types together
    \item Useful for status code-focused queries
\end{itemize}

\subsubsection{Disadvantages}
\begin{itemize}
    \item May fragment related requests with different statuses
    \item Less effective for user journey analysis
    \item Context limited to same-status entries
\end{itemize}

\section{Question-Answer Evaluation}

This section presents the test questions, AI responses from each chunking method, correct answers, and evaluation scores.

\subsection{Test Question 1: User Journey Analysis}

\textbf{Question}: "What sequence of events led to successful checkout for IP 172.16.54.78?"

\subsubsection{log\_semantic\_sliding Response}
The AI provided a detailed sequence but missed some key events. It identified:
\begin{itemize}
    \item Search for "wireless mouse" at 08:41:00
    \item Viewing product item-67
    \item Profile access and settings update
\end{itemize}
However, it missed the actual checkout sequence from the logs.

\subsubsection{Correct Answer}
Based on log analysis, the complete sequence for IP 172.16.54.78 checkout:
\begin{enumerate}
    \item \texttt{08:17:12} - GET /products/item-42 (200)
    \item \texttt{08:17:13} - GET /assets/img/product-42.jpg (200)
    \item \texttt{08:17:14} - POST /cart/add (201) - Item added to cart
    \item \texttt{08:25:00} - GET /products/item-89 (200)
    \item \texttt{08:25:01} - GET /assets/img/product-89.jpg (200)
    \item \texttt{08:25:10} - POST /cart/add (201) - Second item added
    \item \texttt{08:25:30} - GET /checkout (200) - Checkout page accessed
    \item \texttt{08:36:00} - POST /checkout/payment (200) - Payment processed
    \item \texttt{08:36:05} - GET /order/confirmation/ORD-12345 (200) - Order confirmed
\end{enumerate}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_semantic\_sliding}: Score: 6/10 - Good context but incomplete sequence
    \item \textbf{log\_component\_based}: Would perform better (groups by IP)
    \item \textbf{log\_time\_window}: Would miss cross-hour sequences
\end{itemize}

\subsection{Test Question 2: Error Analysis}

\textbf{Question}: "List all 404 errors and their timestamps"

\subsubsection{log\_error\_block Response}
The AI correctly identified:
\begin{itemize}
    \item \texttt{08:15:26} - GET /favicon.ico (404)
    \item \texttt{08:39:02} - GET /nonexistent-page (404)
    \item \texttt{08:39:05} - GET /another-missing (404)
\end{itemize}

\subsubsection{Correct Answer}
All 404 errors in the dataset:
\begin{enumerate}
    \item \texttt{08/Jan/2026:08:15:26} - IP: 192.168.1.45 - GET /favicon.ico (404, 278 bytes)
    \item \texttt{08/Jan/2026:08:39:02} - IP: 192.168.1.89 - GET /nonexistent-page (404, 567 bytes)
    \item \texttt{08/Jan/2026:08:39:05} - IP: 192.168.1.89 - GET /another-missing (404, 567 bytes)
\end{enumerate}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_error\_block}: Score: 9/10 - Excellent, correctly identified all errors
    \item \textbf{log\_status\_code}: Score: 8/10 - Good, groups 4xx together
    \item \textbf{log\_semantic\_sliding}: Score: 7/10 - May miss errors if scattered
\end{itemize}

\subsection{Test Question 3: Time-Based Analysis}

\textbf{Question}: "What was the traffic pattern between 08:00 and 09:00?"

\subsubsection{log\_time\_window Response}
The AI provided a comprehensive analysis:
\begin{itemize}
    \item Identified high traffic at 08:30-08:45
    \item Noted user login patterns
    \item Identified search activity
    \item Mentioned cart operations
    \item Identified bot traffic (robots.txt requests)
\end{itemize}

\subsubsection{Correct Answer}
Traffic pattern analysis (08:00-09:00):
\begin{itemize}
    \item \textbf{08:15-08:20}: Initial page loads, static resources (CSS, JS, images)
    \item \textbf{08:20-08:25}: User authentication, dashboard access, API calls
    \item \textbf{08:25-08:30}: Product browsing, cart operations
    \item \textbf{08:30-08:35}: Search engine crawlers (66.249.66.1 - Googlebot)
    \item \textbf{08:35-08:40}: Admin operations, user management
    \item \textbf{08:40-08:45}: Content browsing (blog, news, gallery)
    \item \textbf{08:45-08:50}: Profile management, settings updates
    \item \textbf{08:50-09:00}: Various endpoints (wishlist, notifications, resources)
\end{itemize}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_time\_window}: Score: 9/10 - Excellent temporal grouping
    \item \textbf{log\_semantic\_sliding}: Score: 7/10 - Good but may split across chunks
    \item \textbf{log\_component\_based}: Score: 5/10 - Fragments time-based patterns
\end{itemize}

\subsection{Test Question 4: Status Code Analysis}

\textbf{Question}: "What percentage of requests were successful (2xx)?"

\subsubsection{log\_status\_code Response}
The AI calculated: 87.5\% successful (12 out of 14 requests shown). However, this was based on a limited sample.

\subsubsection{Correct Answer}
From the complete dataset (150+ entries):
\begin{itemize}
    \item Total requests: ~150 entries
    \item 2xx (Success): ~140 entries (93.3\%)
    \item 3xx (Redirect): 1 entry (304 Not Modified) (0.7\%)
    \item 4xx (Client Error): 6 entries (4.0\%)
    \begin{itemize}
        \item 401 Unauthorized: 3 entries
        \item 403 Forbidden: 1 entry
        \item 404 Not Found: 3 entries
    \end{itemize}
    \item 5xx (Server Error): 0 entries (0\%)
\end{itemize}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_status\_code}: Score: 8/10 - Good grouping but sample size issue
    \item \textbf{log\_error\_block}: Score: 6/10 - Focuses on errors, misses success rate
    \item \textbf{log\_semantic\_sliding}: Score: 7/10 - Can calculate but requires aggregation
\end{itemize}

\subsection{Test Question 5: Authentication Failure Analysis}

\textbf{Question}: "Analyze the authentication failure pattern"

\subsubsection{log\_error\_block Response}
The AI identified:
\begin{itemize}
    \item Two failed admin login attempts (401) from IP 10.0.0.155
    \item Timestamps: 08:28:30 and 08:28:35
    \item Successful login at 08:28:40
    \item Pattern: Failed attempts followed by success
\end{itemize}

\subsubsection{Correct Answer}
Authentication failure pattern analysis:
\begin{itemize}
    \item \textbf{IP Address}: 10.0.0.155
    \item \textbf{Timeline}:
    \begin{enumerate}
        \item \texttt{08:28:00} - GET /admin (403 Forbidden) - Unauthorized access attempt
        \item \texttt{08:28:05} - GET /admin/login (200) - Login page accessed
        \item \texttt{08:28:30} - POST /admin/login (401) - First failed attempt
        \item \texttt{08:28:35} - POST /admin/login (401) - Second failed attempt
        \item \texttt{08:28:40} - POST /admin/login (200) - Successful login
        \item \texttt{08:28:45} - GET /admin/dashboard (200) - Dashboard accessed
    \end{enumerate}
    \item \textbf{Pattern}: Two failed attempts within 5 seconds, then successful on third attempt
    \item \textbf{Security Concern}: Possible brute-force attempt, succeeded after 2 failures
\end{itemize}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_error\_block}: Score: 9/10 - Excellent for error pattern analysis
    \item \textbf{log\_component\_based}: Score: 8/10 - Good IP grouping
    \item \textbf{log\_status\_code}: Score: 7/10 - Groups 401s but may miss sequence
\end{itemize}

\subsection{Test Question 6: Cart Operations Flow}

\textbf{Question}: "Show me the complete flow of cart operations"

\subsubsection{log\_semantic\_sliding Response}
The AI provided a flow but mixed different IP addresses and missed the complete sequence.

\subsubsection{Correct Answer}
Complete cart operations flow (multiple users):
\begin{itemize}
    \item \textbf{User 1 (172.16.54.78)}:
    \begin{enumerate}
        \item \texttt{08:17:14} - POST /cart/add (201) - Added item-42
        \item \texttt{08:25:10} - POST /cart/add (201) - Added item-89
        \item \texttt{08:25:30} - GET /checkout (200)
        \item \texttt{08:36:00} - POST /checkout/payment (200)
        \item \texttt{08:36:05} - GET /order/confirmation/ORD-12345 (200)
    \end{enumerate}
    \item \textbf{User 2 (10.0.0.122)}:
    \begin{enumerate}
        \item \texttt{08:24:20} - DELETE /api/cart/item/5 (204) - Removed item
        \item \texttt{08:24:25} - GET /api/cart (200) - Viewed cart
    \end{enumerate}
    \item \textbf{User 3 (172.16.54.90)}:
    \begin{enumerate}
        \item \texttt{09:09:10} - POST /wishlist/add (201) - Added to wishlist
    \end{enumerate}
\end{itemize}

\subsubsection{Evaluation}
\begin{itemize}
    \item \textbf{log\_component\_based}: Score: 9/10 - Best for user-specific flows
    \item \textbf{log\_semantic\_sliding}: Score: 7/10 - Good context but may mix users
    \item \textbf{log\_time\_window}: Score: 6/10 - May split operations across hours
\end{itemize}

\section{Comparative Analysis}

\subsection{Performance Metrics by Query Type}

\begin{table}[h]
\centering
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Query Type} & \textbf{Semantic} & \textbf{Error} & \textbf{Time} & \textbf{Component} & \textbf{Status} \\
\midrule
User Journey & 7/10 & 4/10 & 6/10 & 9/10 & 5/10 \\
Error Analysis & 7/10 & 9/10 & 6/10 & 7/10 & 8/10 \\
Time Patterns & 7/10 & 5/10 & 9/10 & 5/10 & 6/10 \\
Status Analysis & 7/10 & 6/10 & 6/10 & 6/10 & 8/10 \\
Auth Failures & 6/10 & 9/10 & 6/10 & 8/10 & 7/10 \\
Cart Operations & 7/10 & 5/10 & 6/10 & 9/10 & 5/10 \\
\bottomrule
\textbf{Average} & \textbf{7.0/10} & \textbf{6.3/10} & \textbf{6.5/10} & \textbf{7.3/10} & \textbf{6.5/10} \\
\bottomrule
\end{tabular}
\caption{Performance Scores by Query Type}
\end{table}

\subsection{Strengths and Weaknesses Summary}

\begin{table}[h]
\centering
\small
\begin{tabular}{p{3cm}|p{6cm}|p{6cm}}
\toprule
\textbf{Method} & \textbf{Strengths} & \textbf{Weaknesses} \\
\midrule
\textbf{Semantic Sliding} & 
\begin{itemize}[leftmargin=*,nosep]
    \item Context preservation
    \item General-purpose
    \item Good for complex queries
\end{itemize} &
\begin{itemize}[leftmargin=*,nosep]
    \item Storage overhead
    \item May mix unrelated entries
\end{itemize} \\
\midrule
\textbf{Error Block} & 
\begin{itemize}[leftmargin=*,nosep]
    \item Excellent error analysis
    \item Security incident detection
    \item Error context grouping
\end{itemize} &
\begin{itemize}[leftmargin=*,nosep]
    \item Poor for non-error queries
    \item Fragments normal traffic
\end{itemize} \\
\midrule
\textbf{Time Window} & 
\begin{itemize}[leftmargin=*,nosep]
    \item Temporal analysis
    \item Traffic patterns
    \item Peak hour identification
\end{itemize} &
\begin{itemize}[leftmargin=*,nosep]
    \item Splits cross-hour sequences
    \item Fixed granularity
\end{itemize} \\
\midrule
\textbf{Component Based} & 
\begin{itemize}[leftmargin=*,nosep]
    \item User behavior analysis
    \item Session tracking
    \item IP-based queries
\end{itemize} &
\begin{itemize}[leftmargin=*,nosep]
    \item Fragments time patterns
    \item Multiple IP queries
\end{itemize} \\
\midrule
\textbf{Status Code} & 
\begin{itemize}[leftmargin=*,nosep]
    \item Performance monitoring
    \item Error rate analysis
    \item Status-focused queries
\end{itemize} &
\begin{itemize}[leftmargin=*,nosep]
    \item Fragments user journeys
    \item Limited context
\end{itemize} \\
\bottomrule
\end{tabular}
\caption{Method Comparison}
\end{table}

\section{Recommendations}

\subsection{Best Method for General-Purpose Log Analysis}

Based on the evaluation, \textbf{log\_component\_based} achieves the highest average score (7.3/10) and performs excellently for:
\begin{itemize}
    \item User journey analysis (9/10)
    \item Cart operations (9/10)
    \item Authentication patterns (8/10)
\end{itemize}

However, for a \textbf{comprehensive RAG system} that needs to handle diverse query types, \textbf{log\_semantic\_sliding} is recommended because:
\begin{enumerate}
    \item \textbf{Context Preservation}: 20\% overlap ensures no information loss
    \item \textbf{General-Purpose}: Performs well across all query types (7.0/10 average)
    \item \textbf{RAG Optimization}: Designed specifically for retrieval-augmented generation
    \item \textbf{Flexibility}: Can answer both specific and general questions
\end{enumerate}

\subsection{Hybrid Approach Recommendation}

For production systems, consider a \textbf{hybrid approach}:

\begin{enumerate}
    \item \textbf{Primary Index}: Use \texttt{log\_semantic\_sliding} for general queries
    \item \textbf{Specialized Indexes}: Create additional indexes for specific use cases:
    \begin{itemize}
        \item \texttt{log\_error\_block} for error analysis queries
        \item \texttt{log\_time\_window} for time-based queries
        \item \texttt{log\_component\_based} for user behavior queries
    \end{itemize}
    \item \textbf{Query Router}: Implement intelligent routing based on query intent
\end{enumerate}

\subsection{Configuration Recommendations}

\subsubsection{For log\_semantic\_sliding (Recommended)}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 20\% (500 characters)
    \item Use case: General-purpose RAG system
\end{itemize}

\subsubsection{For log\_error\_block}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0
    \item Use case: Security monitoring, error debugging
\end{itemize}

\subsubsection{For log\_time\_window}
\begin{itemize}
    \item \texttt{chunk\_size}: 3000 characters
    \item \texttt{overlap\_size}: 0
    \item Use case: Traffic analysis, peak hour identification
\end{itemize}

\subsubsection{For log\_component\_based}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0
    \item Use case: User behavior analysis, session tracking
\end{itemize}

\subsubsection{For log\_status\_code}
\begin{itemize}
    \item \texttt{chunk\_size}: 2500 characters
    \item \texttt{overlap\_size}: 0
    \item Use case: Performance monitoring, SLA tracking
\end{itemize}

\section{Conclusion}

This evaluation demonstrates that chunking method selection significantly impacts RAG system performance for log analysis. Key findings:

\begin{enumerate}
    \item \textbf{No single method is optimal for all query types}
    \item \textbf{log\_semantic\_sliding} provides the best balance for general-purpose use
    \item \textbf{Specialized methods} excel in their specific domains:
    \begin{itemize}
        \item \texttt{log\_error\_block} for error analysis
        \item \texttt{log\_time\_window} for temporal queries
        \item \texttt{log\_component\_based} for user behavior
    \end{itemize}
    \item \textbf{Hybrid approaches} offer the best overall performance
\end{enumerate}

For a production log analysis RAG system, we recommend:
\begin{itemize}
    \item Primary: \texttt{log\_semantic\_sliding} with 20\% overlap
    \item Secondary: Specialized indexes for common query patterns
    \item Query routing: Intelligent method selection based on query intent
\end{itemize}

\section{Appendix: Complete Question-Answer Pairs}

\subsection{Question Set 1: log\_semantic\_sliding (chunk\_size: 2500, overlap: 20\%)}

\subsubsection{Question 1.1}
\textbf{Question}: "What sequence of events led to successful checkout for IP 172.16.54.78?"

\textbf{AI Response}: 
\begin{quote}
Based on the log entries provided, here is the sequence of events that led to a successful checkout for IP 172.16.54.78:

1. 08/Jan/2026:08:41:00 - The user accessed the search page with the query "wireless mouse".
2. 08/Jan/2026:08:41:15 - The user viewed a product detail page for item-67.
3. 08/Jan/2026:08:41:20 - The user accessed the image associated with product-67.
4. 08/Jan/2026:08:45:00 - The user accessed their profile page.
5. 08/Jan/2026:08:45:05 - The user viewed the settings section of their profile.
6. 08/Jan/2026:08:45:20 - The user updated their profile settings, which could be related to checkout information.

While there are no explicit log entries for a direct checkout process, it is reasonable to infer that after updating the profile settings, the user proceeded with the checkout. This assumption is based on typical user behavior and the fact that profile updates often precede or coincide with checkout activities.
\end{quote}

\textbf{Correct Answer}: The actual checkout sequence for IP 172.16.54.78 occurred earlier:
\begin{enumerate}
    \item 08:17:12 - GET /products/item-42 (200)
    \item 08:17:13 - GET /assets/img/product-42.jpg (200)
    \item 08:17:14 - POST /cart/add (201)
    \item 08:25:00 - GET /products/item-89 (200)
    \item 08:25:01 - GET /assets/img/product-89.jpg (200)
    \item 08:25:10 - POST /cart/add (201)
    \item 08:25:30 - GET /checkout (200)
    \item 08:36:00 - POST /checkout/payment (200)
    \item 08:36:05 - GET /order/confirmation/ORD-12345 (200)
\end{enumerate}

\textbf{Evaluation}: Score 4/10 - The AI missed the actual checkout sequence and provided incorrect timeline.

\subsubsection{Question 1.2}
\textbf{Question}: "Trace the user journey from search to purchase completion"

\textbf{AI Response}:
\begin{quote}
To trace the user journey from search to purchase completion using the provided log entries, let's follow a specific example:

Example User Journey:
- User IP: 172.16.54.90
- Timestamp: 08/Jan/2026:08:41:00

Step 1: Search for a Product - The user searched for a wireless mouse.
Step 2: View Product Details - After the search, the user viewed details for item-67.
Step 3: View Product Image - The user also viewed the image of the product.
Step 4: Initiate Purchase - The user then initiated the purchase process.
Step 5: Complete Purchase - Finally, the user completed the purchase.

The user searched for a wireless mouse, viewed the details and image of item-67, initiated the purchase process, and completed it successfully.
\end{quote}

\textbf{Correct Answer}: The AI provided a generic example but missed the actual complete purchase journey. A complete journey would include cart operations, checkout, and order confirmation.

\textbf{Evaluation}: Score 5/10 - Generic response, lacks specific details.

\subsubsection{Question 1.3}
\textbf{Question}: "What happened between 08:25:00 and 08:36:05?"

\textbf{AI Response}:
\begin{quote}
Between 08:25:00 and 08:36:05, there were no specific actions or requests logged in the provided entries. The closest activity was a GET request for /dashboard at 08:20:15, which resulted in a 401 Unauthorized status. This suggests that an attempt was made to access the dashboard without proper authentication.

No other significant activities occurred during this time frame based on the logs provided.
\end{quote}

\textbf{Correct Answer}: Multiple activities occurred:
\begin{itemize}
    \item 08:25:00-08:25:30 - Cart operations (item-89 added, checkout accessed)
    \item 08:26:15-08:27:01 - Contact form submission
    \item 08:28:00-08:28:45 - Admin login attempts
    \item 08:30:00-08:30:10 - Blog access
    \item 08:36:00-08:36:05 - Payment processing and order confirmation
\end{itemize}

\textbf{Evaluation}: Score 2/10 - Completely missed the checkout sequence in this time window.

\subsubsection{Question 1.4}
\textbf{Question}: "Show me the complete flow of cart operations"

\textbf{AI Response}:
\begin{quote}
Based on the log entries provided, here is a complete flow of cart operations:

1. User 192.168.1.45 adds an item to the cart (08:17:14)
2. User attempts to access dashboard but is unauthorized (08:20:15)
3. User logs in (08:20:45)
4. User accesses dashboard (08:20:46)
5. User searches for product (08:21:30)
6. User views product (08:21:45)
7. User refreshes home page (08:22:10-08:22:11)

This flow demonstrates the process of adding items to a cart and accessing protected resources after logging in.
\end{quote}

\textbf{Correct Answer}: The AI mixed different users and missed actual cart operations. See Section 4.6 for complete answer.

\textbf{Evaluation}: Score 4/10 - Mixed users, missed actual cart operations.

\subsubsection{Question 1.5}
\textbf{Question}: "What was the user experience for the customer who bought item-89?"

\textbf{AI Response}:
\begin{quote}
Based on the provided log entries, there is no direct information about a customer buying item-89 or their user experience related to that purchase. The logs show various activities and page views but do not include specific transactions or detailed user interactions with individual items like item-89.

To answer this question accurately, we would need additional data such as transaction logs, order confirmation emails, or detailed user interaction logs that capture the entire process of purchasing an item.
\end{quote}

\textbf{Correct Answer}: Customer journey for item-89 (IP 172.16.54.78):
\begin{enumerate}
    \item 08:25:00 - Viewed product item-89
    \item 08:25:01 - Viewed product image
    \item 08:25:10 - Added to cart (POST /cart/add, 201)
    \item 08:25:30 - Accessed checkout page
    \item 08:36:00 - Processed payment
    \item 08:36:05 - Received order confirmation
\end{enumerate}

\textbf{Evaluation}: Score 3/10 - AI stated no information available, but data exists in logs.

\subsection{Question Set 2: log\_error\_block (chunk\_size: 2500, overlap: 0)}

\subsubsection{Question 2.1}
\textbf{Question}: "List all 404 errors and their timestamps"

\textbf{AI Response}:
\begin{quote}
Here are all 404 errors found in the log entries along with their timestamps:

1. Timestamp: 2026-01-08T08:39:05Z, IP: 192.168.1.89, URL: /another-missing
2. Timestamp: 2026-01-08T08:39:02Z, IP: 192.168.1.89, URL: /nonexistent-page
\end{quote}

\textbf{Correct Answer}: All 404 errors:
\begin{enumerate}
    \item 08/Jan/2026:08:15:26 - IP: 192.168.1.45 - GET /favicon.ico (404, 278 bytes)
    \item 08/Jan/2026:08:39:02 - IP: 192.168.1.89 - GET /nonexistent-page (404, 567 bytes)
    \item 08/Jan/2026:08:39:05 - IP: 192.168.1.89 - GET /another-missing (404, 567 bytes)
\end{enumerate}

\textbf{Evaluation}: Score 7/10 - Missed the favicon.ico 404 error at 08:15:26.

\subsubsection{Question 2.2}
\textbf{Question}: "Were there any failed admin login attempts?"

\textbf{AI Response}:
\begin{quote}
Based on the log entries provided, there were no failed admin login attempts. The only admin-related activity shown is a successful GET request to /admin/dashboard by IP 10.0.0.155 at 08:28:45. There are no POST requests or other indications of login attempts in the logs.
\end{quote}

\textbf{Correct Answer}: Yes, there were 2 failed admin login attempts:
\begin{itemize}
    \item 08:28:30 - POST /admin/login (401) from IP 10.0.0.155
    \item 08:28:35 - POST /admin/login (401) from IP 10.0.0.155
\end{itemize}

\textbf{Evaluation}: Score 2/10 - Completely missed the 401 errors, which should be the strength of this method.

\subsubsection{Question 2.3}
\textbf{Question}: "Show me all client errors (4xx) with context"

\textbf{AI Response}:
\begin{quote}
Client Errors (4xx) with Context:

1. Timestamp: 08/Jan/2026:08:28:00, IP: 10.0.0.155, Request: GET /admin HTTP/1.1, Response Code: 403 Forbidden
2. Timestamp: 08/Jan/2026:08:28:05, IP: 10.0.0.155, Request: GET /admin/login HTTP/1.1, Response Code: 403 Forbidden
3. Timestamp: 08/Jan/2026:08:20:15, IP: 10.0.0.122, Request: GET /dashboard HTTP/1.1, Response Code: 401 Unauthorized
4. Timestamp: 08/Jan/2026:08:27:00, IP: 192.168.1.45, Request: POST /contact/submit HTTP/1.1, Response Code: 400 Bad Request
\end{quote}

\textbf{Correct Answer}: The AI listed some errors but:
\begin{itemize}
    \item Incorrectly listed /admin/login as 403 (it was 200)
    \item Missed the actual 401 errors at 08:28:30 and 08:28:35
    \item Listed /contact/submit as 400 (it was 200)
\end{itemize}

\textbf{Evaluation}: Score 5/10 - Found some errors but with incorrect status codes.

\subsubsection{Question 2.4}
\textbf{Question}: "Analyze the authentication failure pattern"

\textbf{AI Response}:
\begin{quote}
Authentication Failure Pattern Analysis

The authentication failure pattern can be identified by looking at failed login attempts and unauthorized access requests. Based on the provided log entries:

1. Failed Login Attempts:
- Timestamp: 08/Jan/2026:08:28:00, IP: 10.0.0.155, Request: GET /admin HTTP/1.1, Status Code: 403 Forbidden
- Timestamp: 08/Jan/2026:08:28:05, IP: 10.0.0.155, Request: GET /admin/login HTTP/1.1, Status Code: 200 OK

2. Unauthorized Access Requests:
- Timestamp: 08/Jan/2026:08:27:01, IP: 192.168.1.45, Request: GET /contact/submit HTTP/1.1, Status Code: 200 OK

3. Successful Login Attempts:
- Timestamp: 08/Jan/2026:08:28:05, IP: 10.0.0.155, Request: GET /admin/login HTTP/1.1, Status Code: 200 OK

Summary: The authentication failure pattern shows that an IP address attempted to access restricted resources but was denied permission. There is a discrepancy between the failed attempt and successful access for the same user, which could indicate a potential security issue or misconfiguration.
\end{quote}

\textbf{Correct Answer}: See Section 4.5 for complete analysis.

\textbf{Evaluation}: Score 6/10 - Identified some patterns but missed the actual 401 POST requests.

\subsection{Question Set 3: log\_time\_window (chunk\_size: 3000, overlap: 0)}

\subsubsection{Question 3.1}
\textbf{Question}: "What was the traffic pattern between 08:00 and 09:00?"

\textbf{AI Response}:
\begin{quote}
Between 08:00 and 09:00, there was a significant increase in traffic on the server. Here are some key points:

1. High Traffic at 08:30-08:45: Multiple IP addresses accessed various product pages and images, indicating a surge in user activity.

2. User Login and Dashboard Access: At 08:20, an IP address attempted to access the dashboard but was denied due to a missing session (HTTP 401). The same user then successfully logged in at 08:20:45 and accessed the dashboard again.

3. Search Activity: At 08:21, an IP address performed a search for "laptop," which led to another product page being accessed.

4. Cart Operations: At 08:24, an IP address deleted an item from their cart and then checked the cart contents again.

5. Robots.txt and Sitemap.xml Requests: Multiple requests for robots.txt and sitemap.xml were made during this period, which are typically used by search engine crawlers.
\end{quote}

\textbf{Correct Answer}: See Section 4.3.

\textbf{Evaluation}: Score 8/10 - Good temporal analysis, identified key patterns.

\subsubsection{Question 3.2}
\textbf{Question}: "When was the peak traffic hour?"

\textbf{AI Response}:
\begin{quote}
Based on the log entries provided, the peak traffic hour appears to be around 8:00 AM to 9:00 AM. This can be inferred from several factors:

1. High Volume of Requests: During this time, there is a significant increase in the number of requests being made to the server.

2. Frequent Repeated Requests: Some IPs are making repeated requests within short intervals, indicating active user engagement.

3. Resource Caching: Some responses indicate that certain resources are being cached, which could be a result of high traffic.
\end{quote}

\textbf{Correct Answer}: Peak traffic occurred between 08:15-09:00, with highest activity around 08:25-08:45 (checkout operations, admin activities, content browsing).

\textbf{Evaluation}: Score 7/10 - Correctly identified peak hour but lacked specific timing.

\subsubsection{Question 3.3}
\textbf{Question}: "How many requests occurred at 08:15?"

\textbf{AI Response}:
\begin{quote}
Based on the log entries provided, there were no requests that occurred at 08:15. The closest timestamps to 08:15 are:

- 10.0.0.155 - POST /admin/backup HTTP/1.1 at 09:15:00
- 10.0.0.155 - GET /admin/backup/status HTTP/1.1 at 09:15:30

All other requests in the logs occurred at different times, so there were no requests at exactly 08:15.
\end{quote}

\textbf{Correct Answer}: There were 5 requests at 08:15:
\begin{enumerate}
    \item 08:15:23 - GET /index.html (200)
    \item 08:15:24 - GET /assets/css/style.css (200)
    \item 08:15:24 - GET /assets/js/main.js (200)
    \item 08:15:25 - GET /assets/img/logo.png (200)
    \item 08:15:26 - GET /favicon.ico (404)
\end{enumerate}

\textbf{Evaluation}: Score 1/10 - Completely missed the entries at 08:15:23-08:15:26.

\subsubsection{Question 3.4}
\textbf{Question}: "Compare activity at 08:30 vs 09:00"

\textbf{AI Response}:
\begin{quote}
To compare activity at 08:30 vs 09:00, let's look at some specific examples from the log entries:

Activity at 08:30:
- 10.0.0.122 - GET /api/users HTTP/1.1 (08:30:01)
- 10.0.0.122 - POST /api/login HTTP/1.1 (08:30:02)
- 172.16.54.78 - GET /products/item-42 HTTP/1.1 (08:30:12)
- 192.168.1.67 - GET /about.html HTTP/1.1 (08:30:30)

Activity at 09:00:
- 10.0.0.122 - DELETE /api/cart/item/5 HTTP/1.1 (09:00:20)
- 172.16.54.78 - GET /checkout HTTP/1.1 (09:00:30)

Key Observations:
1. User Activity: At 08:30, there were multiple API calls and page views. At 09:00, the activity focused more on cart operations and checkout processes.
2. IP Addresses: The same IP address (10.0.0.122) was active at both times.
3. Page Views: At 08:30, the /about.html page was accessed once. At 09:00, no specific pages were accessed; instead, there were cart-related operations.
\end{quote}

\textbf{Correct Answer}: The AI provided some examples but timestamps are incorrect. Actual activity:
\begin{itemize}
    \item \textbf{08:30}: Blog access, gallery viewing, forum activity
    \item \textbf{09:00}: Deals browsing, API calls (recommendations, trending), events registration
\end{itemize}

\textbf{Evaluation}: Score 5/10 - Provided comparison but with incorrect timestamps.

\subsection{Question Set 4: log\_component\_based (chunk\_size: 2500, overlap: 0)}

\subsubsection{Question 4.1}
\textbf{Question}: "What percentage of requests were successful (2xx)?"

\textbf{AI Response}:
\begin{quote}
Answer: 87.5\% of requests were successful (2xx).

Details:
- Out of 14 total requests in the provided log entries:
- Successful requests (2xx): 12
- Failed requests (non-2xx): 2
\end{quote}

\textbf{Correct Answer}: From complete dataset: ~93.3\% (140/150 entries).

\textbf{Evaluation}: Score 6/10 - Limited sample size, but calculation method correct.

\subsubsection{Question 4.2}
\textbf{Question}: "How many redirect responses (3xx) occurred?"

\textbf{AI Response}:
\begin{quote}
Answer: There were no redirect responses (3xx) in the provided log entries.

The log entries only show successful (2xx), client error (4xx), and server error (5xx) responses. No 3xx status codes indicating redirects are present.
\end{quote}

\textbf{Correct Answer}: There was 1 response with 3xx category: 304 Not Modified (cached resource).

\textbf{Evaluation}: Score 8/10 - Correctly identified no true redirects, though 304 is technically 3xx.

\subsubsection{Question 4.3}
\textbf{Question}: "List all 401 unauthorized attempts"

\textbf{AI Response}:
\begin{quote}
Answer: There were 2 unauthorized attempts (401) recorded in the provided log entries.

Details:
- Unauthorized attempt 1: Timestamp: [08/Jan/2026:08:28:30 -0500], IP Address: 10.0.0.155, Request: POST /admin/login HTTP/1.1, Status Code: 401 (Unauthorized), Size: 345 bytes
- Unauthorized attempt 2: Timestamp: [08/Jan/2026:08:28:35 -0500], IP Address: 10.0.0.155, Request: POST /admin/login HTTP/1.1, Status Code: 401 (Unauthorized), Size: 345 bytes
\end{quote}

\textbf{Correct Answer}: Correct! There were 2 unauthorized attempts, plus 1 at 08:20:15 (GET /dashboard, 401).

\textbf{Evaluation}: Score 9/10 - Excellent, correctly identified the admin login failures.

\subsubsection{Question 4.4}
\textbf{Question}: "Were there any 5xx server errors?"

\textbf{AI Response}:
\begin{quote}
Answer: There were no 5xx server errors recorded in the provided log entries.

The log entries only show successful (2xx), client error (4xx), and redirect (3xx) responses. No 5xx status codes indicating server errors are present.
\end{quote}

\textbf{Correct Answer}: Correct - no 5xx errors in the dataset.

\textbf{Evaluation}: Score 10/10 - Perfect answer.

\subsection{Question Set 5: log\_status\_code (chunk\_size: 2500, overlap: 0)}

\subsubsection{Question 5.1}
\textbf{Question}: "What percentage of requests were successful (2xx)?"

\textbf{AI Response}:
\begin{quote}
Answer: 87.5\% of requests were successful (2xx).

Details:
- Out of 14 total requests in the provided log entries:
- Successful requests (2xx): 12
- Failed requests (non-2xx): 2
\end{quote}

\textbf{Correct Answer}: ~93.3\% from complete dataset.

\textbf{Evaluation}: Score 6/10 - Limited sample, but method correct.

\subsubsection{Question 5.2}
\textbf{Question}: "How many redirect responses (3xx) occurred?"

\textbf{AI Response}:
\begin{quote}
Answer: There were no redirect responses (3xx) in the provided log entries.

The log entries only show successful (2xx), client error (4xx), and server error (5xx) responses. No 3xx status codes indicating redirects are present.
\end{quote}

\textbf{Correct Answer}: 1 response with 304 Not Modified.

\textbf{Evaluation}: Score 8/10 - Correct for practical purposes.

\subsubsection{Question 5.3}
\textbf{Question}: "List all 401 unauthorized attempts"

\textbf{AI Response}:
\begin{quote}
Answer: There were 2 unauthorized attempts (401) recorded in the provided log entries.

Details:
- Unauthorized attempt 1: Timestamp: [08/Jan/2026:08:28:30 -0500], IP Address: 10.0.0.155, Request: POST /admin/login HTTP/1.1, Status Code: 401 (Unauthorized), Size: 345 bytes
- Unauthorized attempt 2: Timestamp: [08/Jan/2026:08:28:35 -0500], IP Address: 10.0.0.155, Request: POST /admin/login HTTP/1.1, Status Code: 401 (Unauthorized), Size: 345 bytes
\end{quote}

\textbf{Correct Answer}: 2 admin login failures, plus 1 dashboard access failure.

\textbf{Evaluation}: Score 8/10 - Good, identified the main failures.

\subsubsection{Question 5.4}
\textbf{Question}: "Were there any 5xx server errors?"

\textbf{AI Response}:
\begin{quote}
Answer: There were no 5xx server errors recorded in the provided log entries.

The log entries only show successful (2xx), client error (4xx), and redirect (3xx) responses. No 5xx status codes indicating server errors are present.
\end{quote}

\textbf{Correct Answer}: Correct - no 5xx errors.

\textbf{Evaluation}: Score 10/10 - Perfect.

\subsubsection{Question 5.5}
\textbf{Question}: "Which endpoints returned 404?"

\textbf{AI Response}:
\begin{quote}
Answer: The endpoint that returned a 404 (Not Found) status code was /another-missing.

Details:
- Timestamp: [08/Jan/2026:08:39:05 -0500]
- IP Address: 192.168.1.89
- Request: GET /another-missing HTTP/1.1
- Status Code: 404 (Not Found)
- Size: 567 bytes
\end{quote}

\textbf{Correct Answer}: Three endpoints returned 404:
\begin{enumerate}
    \item /favicon.ico (08:15:26)
    \item /nonexistent-page (08:39:02)
    \item /another-missing (08:39:05)
\end{enumerate}

\textbf{Evaluation}: Score 4/10 - Missed 2 out of 3 endpoints.

\subsubsection{Question 5.6}
\textbf{Question}: "Show me all non-200 status codes"

\textbf{AI Response}:
\begin{quote}
Answer: The non-200 status codes recorded in the provided log entries are:

1. 401 Unauthorized (2 instances)
2. 404 Not Found (1 instance)
\end{quote}

\textbf{Correct Answer}: Non-200 status codes:
\begin{itemize}
    \item 304 Not Modified (1 instance)
    \item 401 Unauthorized (3 instances)
    \item 403 Forbidden (1 instance)
    \item 404 Not Found (3 instances)
\end{itemize}

\textbf{Evaluation}: Score 5/10 - Missed 304, 403, and some instances.

\end{document}
